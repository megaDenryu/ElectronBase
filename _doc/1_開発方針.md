# AIが実装するときに守るべき流れ
AIがプログラムを書く場合、実装を完成させることは最終的な目標ですが、拙速にそこに向かうと不可能になります。
AIユーザーもエンジニアであり
細かく層や責務が分けられていて、適切にDIされていて、アーキテクチャが守られた実装というのは結果は欲しいですが、一方で日本語による指示は抽象的であり、具体的ではなく必ず不明事項が存在するのでいきなり具体的に実装すると変更困難性やユーザーが思っていない具体的実装によって追加実装が困難になります。
なので実装するには以下のような適切な段階を踏む必要があります。基本的な思想は、ユーザーが抽象的なことを言っているのだからコードも抽象的に書くべきで、具体実装には安易に踏み込むべきではないということです。実際ユーザーは本当に抽象的なものを望んでいるからです。

## 関数の分類
まずクラスを実装する観点では次のように分類できます。
まず同時に複数クラスを作ろうとすることはあります。
そして、そのとき、作ろうとしているクラスは実装が確定していません。一方その他のクラスは実装が確定しています。
つまり実装しようとしているクラスには外部から複数のインターフェースがdiされるわけですが、これらを使用するという観点で以下のようににクラス内関数には階層がある。
まず、関数には
1. 実装が確定している関数: 具体関数
2. 実装が確定していない関数: 抽象関数
の２種類がある。
AI使役者がAIにやりたいことを伝える場合、やりたいことが漠然としているので関数呼び出しの最低レイヤーの部分は具体関数にすると、やりたいこととずれうる。つまり、完全な実装は無理である。
したがって、以下のようにクラス内のメンバメソッドに対してレベルを定義する。
LV0メソッド: 具体関数にのみ依存するメソッド
LV1メソッド: 具体関数と抽象関数の両方に依存する関数
LV2メソッド: 抽象関数のみに依存する関数
# 第一段階
さて、何かの機能を実装するとき、AIがやるべき第一段階は以下の３つを達成することである。
1. 基本的にやりたいこと用のクラスを切る
2. privateメソッドかpublicメソッドかに関係なくクラス内のもメソッド名と型定義だけ行う(publicメソッドのみを定義するインターフェースとは異なる。)
3. LV2関数のみ実装は書き、LV1とLv0については実装しない。
これは何をやりたいかの細かいことが決まっていないため、意味不明な実装が足かせになりうるからである。

最も最悪なのはconsole.logなどで表示するのもLv1なのでそういうこともしないこと。

# 第二段階
第一段階が終わると、ユーザーも抽象構造が明確になり、具体的なことが考えられるようになります。ここから具体実装が始まります。

# 開発方針
スクリプトはすべてクラスモジュールとして作りDIを意識する。
責務ごとに細かくクラスを分けること。

エレクトロンルートには実装は書かない。各イベント定義関数には対応するイベントオブジェクトを用意し、インターフェースの呼び出しだけを行うこと。
例えばonWehnReadyの中ではOnWhenReadyクラスのexec()だけを行い、実装はOnWhenReadyクラスに任せるような形をとること。これにより、各工程で依存が明確になる。

# LV2メソッドの具体化の工程
AIがまずある程度の抽象構造が決めてコードを出力したあと、コードにはLV2メソッドが存在している。ユーザーは各LV2メソッドを確認してその中身としての具体的なイメージについて日本語でコメントを記述することを具体化準備作業という。
その後再度AIに投げ、AIはコメントを読んで対象のLV1やLv0メソッドを具体化するわけだが、具体化進捗度合いのような概念が登場する。
つまり、LV0もLV1も進捗が0%と100%の間ということは具体関数も書いているが、新たに具体関数にできない抽象関数が出現するということである。そしてその抽象関数はLvv2やLv1として現れるのである。

# 異なるアプローチ
最初にユーザーが大枠をコードで示し、穴埋めをAIが行うということもある。
その際、穴埋めをどのように行うかが問題になる。つまり、ユーザーはなんとなくで書いているのでどこかに穴が開いてることは知ってるが、それがどこかはわからないのである。
そして穴の中にはやりたいことが即座に判断できる「埋め忘れた穴」と、そもそもどうするかすぐには判断できない「本当の穴」がある。
穴埋めをAIが行う場合、AIは最初に「埋め忘れた穴」をユーザーに埋めてもらうことを依頼することである。そのためにすべてのあなをユーザに提示し、埋め忘れた穴をなくしてもらう必要があるのである。
そのためにも


# エレクトロンアプリで実現したいこと
優先度は数値が低いものほど優先する。つまり、優先度１が一番上。未定はまだやらない。
- [x]  [優先度1]ランチャーアプリとして作るのでランチャーUIのページを表示する。ページに表示する内容は決まっていないが、すくなくともLV2UIComponentとしてviewは実装する.
  - [x]  [優先度2]実際に呼び出してウインドウに表示させるところまで行きたい。
  - [x]  [優先度1]ウインドウにランチャーUIのページが表示されないので表示する。

- [x]  [優先度1]エレクトロンアプリがwindowsアプリとしてアクティブウインドウでなくてもショートカットキーで何かしらの関数を実行できるようにしたい。用途としては例えば、Ctrl+Cでコピーした文章をショートカットキーを押すだけでpythonサーバーにwebリクエストとして投げて音声合成を実行したい。そのためにもとにかく、このプロジェクトで定義された関数が実行できるようにしたい。
  - [x]  [優先度2]ショートカットキーの値オブジェクトと、実行コマンドオブジェクトを作り、さらにそのペアを管理するような仕組み、実行する仕組みが欲しい。
- [ ]  [未定]pythonサーバーを立ち上げるが、間違いなくエレクトロンをビルドした後はpythonからビルドされたexeを実行する形になるはず。一方開発中はユーザーが手動でpythonサーバーを起動するのでエレクトロンから常に起動するのは面倒。というかpythonのexeがビルドされていないし、そもそもどのexeを実行するかも決まっていない。
- [ ]  
- [ ]  

# UIデザインについての考察
UIの見た目が今黒なので、RandomColor.tsを用いて、もっと優しい色使いにする。コンセプトが相変わらず決まっていないので難しいが、単なるツールとゲームと動画とウェブサイトではそれぞれデザインの指向性が違うのはなぜか？ボイスロイドアプリは何を目指すか？それはやはり生活と一体になることである。
例えばぽかぽかレモンという飲み物のデザインは目的がデザインから逆算できる。ぽかぽかしたいときには人間が暖色を求める。だからオレンジぽい。しかしレモンなので黄色のはずであるそこからレモンと暖色オレンジの間を取って全体としてはレモン色を強めにしているのかもしえない。テンプレのようなデザインである。
では、ボイロアプリは生活と一体になることを目指すのなら家具とか、ベッドがあればいいのか？短絡的であるが、これはどういうことか？
設定画面も統一感が必要である。背景の画像とかをかえるだけでだいぶましになるのかもしれない。壁紙はあってもいいかもしれない。

# 直近の課題の書き出し
とりあえずデザインはともかく機能を配置していく必要がある。
## 設定画面
設定画面をランチャーに配置したいが、余計な項目が多いのでそれを削除する。（優先度低い）
設定画面にフォルダ移行用のボタンを配置する。しかし、オブジェクトインプットを使っているので、１個階層を深くして、それ以外のボタンも配置可能にする必要がある。
## キャラ画像なしで使える音声合成モードの機能
キャラ画像なしで使える音声合成モードの機能を考えると、
1. キャラ起動選択パネル
2. キャラ設定パネル
3. ショートカットキーで音声送信。しかし音声再生をどのキャラにやらせるかは微妙に問題である。OneONet側の使用中のキャラにしゃべらせたい場合もあるし、画像を出さないでランチャーでやりたいときもある。それから音声認識させてるキャラとは違うキャラにコピペで飛ばしたいという需要もある。
   1. 需要ごとに操作法を変えるというのが確実ではある。使用中キャラの状態をサーバーで管理し、１体だけしか使用できないようにする。それから起動中のキャラ一覧を出し、そのキャラを選択するとそこにショートカットキーでメッセージを飛ばせるようになる。
   2. キャラ１にはショートカットキー１で、キャラ２にはショートカットキー２でといった仕様がいいかも。
4. 音声履歴パネル（文章コピーボタン、再生、停止）

機能だけなら既存コンポーネントを使いまわせる。しかし、デザイン的に問題があるのでそのままではだめそう。
段階的なことを考えれば、とりあえず、ブラウザで動いている使用中のキャラにショートカットで送ることだ。しかしよく考えると、使用中は音声認識も動いているので微妙に使いにくいかも。
使用中キャラを集計することは簡単なのでやはり、だれにショートカットを送るかのUIは必要だろう。
そしてランチャーだけで再生する機構は第２ステップだと思う。何せAIとの関連しているので適切に作らないといけない。
そのためにはpython側のHuman周りを修正しないといけない。各ボイスロイドHumanはTTSアクセサー的なシングルトンの責務もおってしまってるので分割する。

ブラウザ側とエレクトロン側両方の起動キャラクターをエレクトロン側に送る。つまり、キャラインスタンスマネージャーに追加されるたびに両方に送信する必要がある。
websocketでキャラが追加されるたびにエレクトロン側に通知する必要がある。
よく見るとそもそもエレクトロン側はwebsocketがプリミティブに扱われていて構造化されてないのでAppVoiroStudioを参考にリファクタする必要がある。
エレクトロンのキャラスイッチではブラウザ側かエレクトロン側のキャラクターかどうか場所を示す。

エレクトロンからキャラを起動したとき、起動リクエストのレスポンスでも起動中キャラリストに表示されますが、websocketからも通知されて２つ表示されてしまいます。なのでwebsocketでのみ表示更新するようにしたいです。
またブラウザ側からすでに起動していたり反映されなかったりもします。
なのでこれらを解決するために起動中キャラリストにはサーバーの状態が変わるたびに起動中キャラの状態自体をwebsocketで送信し表示リストを更新するときにキャラIDなどから差分を検出して更新する形にしてほしいです。

Python側からのWebSocket通知


ショートカットを押したらサーバーにクリップボードの文字列が送信されるようにし、サーバー側はその文字列をうけとったら送信先のキャラクターの音声を合成し、対象のクライアントに送信する。ここで恐らくまだ送信先キャラクターをエレクトロンで選択したときにそれをサーバーに教える機能はまだ作ってないはずなので一緒に開発する。

キャラリストのキャラボタンの横に停止ボタンを追加し、サーバー側でも対象キャラのHumanNoImageのインスタンスを削除するようにする。ただしブラウザ側のキャラには停止ボタンは出さない。

ランチャー側で音声再生


これらをさらに実行してください